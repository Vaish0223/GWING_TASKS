{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a678cc-c543-44df-84d3-e7e48a6e3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244396e-065b-41c9-bff7-fa5f1625dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676e5ce-251f-4284-8467-76da403fae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae7e85-d89c-4119-bbac-362df87548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3c158-aeee-46a8-a95c-0c7ab37d5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.19.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacbed1-35f6-4317-8a2b-e764f4a4a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714f596-a84f-4d8b-b7ff-b0b0ed7c6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698076d9-a947-4575-b26a-f1b36a0f50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068e829-5b20-49e2-9ecf-d21fea9af5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c72089-ef19-49f9-987a-f0a6c0636975",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621207c8-4cc0-48c9-afe7-a197655f6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7c297-a3f0-4378-b020-c4b8cfa98ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
    "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d69fa-3a06-471b-930c-29550ea199cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_word[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22db5a-5cf3-431a-9656-47c72ae13dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6739d-cd89-43f4-ae7c-b827632381ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e2ea4-0b01-4425-b1cd-d1400c9ed0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, batch_size=128, epochs=5, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e216733-a4d5-4893-9789-bf8c8800e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"text_gen_model2.h5\")\n",
    "with open(\"history2.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b4487-a350-4500-8353-a7076d6c9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"text_gen_model2.h5\")\n",
    "history = pickle.load(open(\"history2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c9db7-3577-40c5-871d-f5c5339cddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b124d1-1d55-4097-b9dc-463e72c4e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible = predict_next_word(\"I will have to look into this thing because I\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9dcfb-0e3e-4b9d-8ea2-e4b68fee9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449315ff-38ab-4e67-8f91-4174ba1eef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee562ea-5354-429b-8125-065112698a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(\"I will have to look into this thing because I\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00759ffd-8dde-4434-b498-01cddd4372e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(\"The president of the United States announced yesterday that he\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e248995-ba73-41bf-a897-fb897fe59bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in predict_next_word(\"The president will most likely not be there to help\", 5):\n",
    "    print(unique_tokens[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
